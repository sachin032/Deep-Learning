{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries from Keras Fashion Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sachin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sachin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sachin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sachin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sachin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sachin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(train_X,train_Y),(test_X,test_Y) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.29411766],\n",
       "         [0.05882353]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.2509804 ],\n",
       "         [0.14901961],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils  import to_categorical\n",
    "import  matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape ::  (60000, 28, 28) [9 0 0 ... 3 0 5]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Shape :: \",train_X.shape , train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Shape ::  (10000, 28, 28) [9 2 1 ... 8 1 5]\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Data Shape :: \",test_X.shape,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Outcomes ::  10\n",
      "Target Outcomes          ::  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of Outcomes :: \", len(np.unique(train_Y)))\n",
    "print(\"Target Outcomes          :: \",np.unique(train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ground Truth : 9')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_X[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(train_Y[0]))\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_X[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(test_Y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape 28*28 pixels to column vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train__X = train_X.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = test_X.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All the feature vectors are in the range of 0-255 so we must normalize them within the range of 0-1 \n",
    "## for better results and algorithmic operations\n",
    "train_X = train__X/255\n",
    "test_X = test_X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 60k training samples of (28*28) and 1 target variable of range (0-9)\n",
    "# we must perform one hot encoding on categorical target column for better results\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: 9\n",
      "After conversion to one-hot: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "## check the shape of test_Y and train_Y now \n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break training set to Training and validation to check overfitting of the model before applying to Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_X sample shape::  (48000, 28, 28, 1)\n",
      "Train_lable sample shape::  (48000, 10)\n",
      "\n",
      "\n",
      "Validation_X sample shape::  (12000, 28, 28, 1)\n",
      "Validation_lable sample shape::  (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train_X sample shape:: \",train_X.shape)\n",
    "print(\"Train_lable sample shape:: \",train_label.shape)\n",
    "print(\"\\n\")\n",
    "print(\"Validation_X sample shape:: \",valid_X.shape)\n",
    "print(\"Validation_lable sample shape:: \",valid_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "num_classes = 10\n",
    "input_shape = (None,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(28,28,1)))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.25))\n",
    "fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.25))\n",
    "fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.4))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation='linear'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))           \n",
    "fashion_model.add(Dropout(0.3))\n",
    "fashion_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 97s 2ms/step - loss: 0.6036 - acc: 0.7747 - val_loss: 0.3754 - val_acc: 0.8574\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 86s 2ms/step - loss: 0.3785 - acc: 0.8612 - val_loss: 0.3117 - val_acc: 0.8819\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 92s 2ms/step - loss: 0.3274 - acc: 0.8782 - val_loss: 0.2849 - val_acc: 0.8925\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 99s 2ms/step - loss: 0.2992 - acc: 0.8882 - val_loss: 0.2629 - val_acc: 0.8994\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 90s 2ms/step - loss: 0.2835 - acc: 0.8948 - val_loss: 0.2489 - val_acc: 0.9070\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 98s 2ms/step - loss: 0.2710 - acc: 0.8993 - val_loss: 0.2505 - val_acc: 0.9071\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 93s 2ms/step - loss: 0.2562 - acc: 0.9045 - val_loss: 0.2406 - val_acc: 0.9116\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 96s 2ms/step - loss: 0.2459 - acc: 0.9092 - val_loss: 0.2290 - val_acc: 0.9154\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 90s 2ms/step - loss: 0.2386 - acc: 0.9114 - val_loss: 0.2279 - val_acc: 0.9171\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 96s 2ms/step - loss: 0.2319 - acc: 0.9109 - val_loss: 0.2312 - val_acc: 0.9178\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 99s 2ms/step - loss: 0.2248 - acc: 0.9161 - val_loss: 0.2224 - val_acc: 0.9179\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 92s 2ms/step - loss: 0.2223 - acc: 0.9159 - val_loss: 0.2202 - val_acc: 0.9189\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 86s 2ms/step - loss: 0.2168 - acc: 0.9186 - val_loss: 0.2273 - val_acc: 0.9182\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 94s 2ms/step - loss: 0.2114 - acc: 0.9200 - val_loss: 0.2116 - val_acc: 0.9234\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 95s 2ms/step - loss: 0.2093 - acc: 0.9215 - val_loss: 0.2240 - val_acc: 0.9200\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 85s 2ms/step - loss: 0.2054 - acc: 0.9226 - val_loss: 0.2193 - val_acc: 0.9225\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 84s 2ms/step - loss: 0.2031 - acc: 0.9238 - val_loss: 0.2101 - val_acc: 0.9249\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 92s 2ms/step - loss: 0.2012 - acc: 0.9241 - val_loss: 0.2169 - val_acc: 0.9227\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 86s 2ms/step - loss: 0.1975 - acc: 0.9252 - val_loss: 0.2055 - val_acc: 0.9270\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 88s 2ms/step - loss: 0.1960 - acc: 0.9259 - val_loss: 0.2199 - val_acc: 0.9221\n"
     ]
    }
   ],
   "source": [
    "fashion_train_dropout = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 356,234\n",
      "Trainable params: 356,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fashion_model.build(input_shape)\n",
    "fashion_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
