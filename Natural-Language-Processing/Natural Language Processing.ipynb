{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/imp.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to link regarding\n",
    " [NLP for beginners]\n",
    "\n",
    "[NLP for beginners]: https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/\n",
    "\n",
    "[NLP for beginners]: http://kavita-ganesan.com/text-preprocessing-tutorial/#.XOeZXlUzZVY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Normalization\n",
    "*  converting letters to lower or upper case\n",
    "*  converting numbers into words or removing numbers\n",
    "*  removing punctuations, accent marks and other diacritics\n",
    "*  removing white spaces\n",
    "*  expanding abbreviations\n",
    "*  removing stop words, sparse terms, and particular words\n",
    "*  text canonicalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Noise removal can be achieved based on two basic approaches\n",
    "* Regualr Expression (look for specific patterns in the text and remove it)\n",
    "* crackdown the noise manually (look against predefined keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list out predefined words\n",
    "noisyWords = [\"is\",\"and\",\"a\",\"'''\",\"-\",\")\",\"(\",\"[\",\"]\",\"of\",\"the\",\"am\",\"are\",\"was\",\"were\",\",\",\"?\",\"#\",\"%\",\"&\",\"|\",\"\\\\\",\"/\",\"*\",\":\",\".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Noise from the text data.\n",
    "def noiseRemoval(textData):\n",
    "    words = textData.split()\n",
    "    noise_free_words =  [word for word in words if word not in noisyWords]\n",
    "    noise_free_text = \" \".join(noise_free_words) \n",
    "    return noise_free_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Give the data File path/home/sachin/Desktop/data.txt\n"
     ]
    }
   ],
   "source": [
    "# Data File path\n",
    "dataFilePath = input(\"\\nGive the data File path\")\n",
    "# /home/sachin/Desktop/data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is how sample data look like\n",
    "\n",
    "Introduction\n",
    "According to industry estimates, only 21% of the available data is present in structured form. Data is being generated as we speak,as we tweet, as we send messages on Whatsapp and in various other activities. Majority of this data exists in the textual form, which is highly unstructured in nature.Few notorious examples include – tweets & facebook [this is intionally injected to make it look worst] / posts on social media, user to user chat conversations, news, blogs and articles, product or services reviews and patient records in the healthcare sector. A few more recent ones includes chatbots and other voice driven bots (intentionally injected this statement to create more noise :) hahha ) .Despite having high dimension data, the information present in it is not directly accessible unless it is processed (read and understood) manually or analyzed by an automated system.In order to produce significant and actionable insights from text data, it is important to get acquainted with the techniques and principles of Natural Language Processing (NLP).So, if you plan to create chatbots this year, or you want to use the power of unstructured text, this guide is the right starting point. This guide unearths the concepts of natural language processing, its techniques and implementation. We can have data like sachin.mishra.in@gmail.com or in form of  $sachin%23%12LPA#India.\n",
    "And i am sure that i am gonna crack NLU & NLP thing crack down very soon. \n",
    "\n",
    "Introduction to Natural Language Processing\n",
    "NLP is a branch of data science that consists of systematic processes for analyzing, understanding, and deriving information from the text data in a smart and efficient manner. By utilizing NLP and its components, one can organize the massive chunks of text data, perform numerous automated tasks and solve a wide range of problems such as – automatic summarization, machine translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, and topic segmentation etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataReadOps(dataPath):\n",
    "    with open(dataPath,\"r\") as f:\n",
    "        dataFile = f.read()\n",
    "        return dataFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = dataReadOps(dataFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noiseFreeData = noiseRemoval(dataFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Basically, noise removal of noise using above two approaches is not the end of normalization. We need to know what are the root of word, Let's Strech it further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Normalization\n",
    "*    Stemming\n",
    "*    Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Stemming using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "import fileinput\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "for line in fileinput.input('/home/sachin/Desktop/data.txt', inplace=True, backup='.bak'):\n",
    "    line = ' '.join([lem.lemmatize(w) for w in line.rstrip().split()])\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is how after first step of noise removal and lemmatization looks like\n",
    "'Introduction According to industry estimates, only 21% available data present in structured form. Data being generated as we speak,as we tweet, as we send messages on Whatsapp in various other activities. Majority this data exists in textual form, which highly unstructured in nature.Few notorious examples include – tweets facebook [this intionally injected to make it look worst] posts on social media, user to user chat conversations, news, blogs articles, product or services reviews patient records in healthcare sector. A few more recent ones includes chatbots other voice driven bots (intentionally injected this statement to create more noise :) hahha .Despite having high dimension data, information present in it not directly accessible unless it processed (read understood) manually or analyzed by an automated system.In order to produce significant actionable insights from text data, it important to get acquainted with techniques principles Natural Language Processing (NLP).So, if you plan to create chatbots this year, or you want to use power unstructured text, this guide right starting point. This guide unearths concepts natural language processing, its techniques implementation. We can have data like sachin.mishra.in@gmail.com or in form $sachin%23%12LPA#India. And i sure that i gonna crack NLU NLP thing crack down very soon. Introduction to Natural Language Processing NLP branch data science that consists systematic processes for analyzing, understanding, deriving information from text data in smart efficient manner. By utilizing NLP its components, one can organize massive chunks text data, perform numerous automated tasks solve wide range problems such as – automatic summarization, machine translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, topic segmentation etc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer \n",
    "stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Introduction According to industry estimates, only 21% available data present in structured form. Data being generated as we speak,as we tweet, as we send messages on Whatsapp in various other activities. Majority this data exists in textual form, which highly unstructured in nature.Few notorious examples include – tweets facebook [this intionally injected to make it look worst] posts on social media, user to user chat conversations, news, blogs articles, product or services reviews patient records in healthcare sector. A few more recent ones includes chatbots other voice driven bots (intentionally injected this statement to create more noise :) hahha .Despite having high dimension data, information present in it not directly accessible unless it processed (read understood) manually or analyzed by an automated system.In order to produce significant actionable insights from text data, it important to get acquainted with techniques principles Natural Language Processing (NLP).So, if you plan to create chatbots this year, or you want to use power unstructured text, this guide right starting point. This guide unearths concepts natural language processing, its techniques implementation. We can have data like sachin.mishra.in@gmail.com or in form $sachin%23%12LPA#India. And i sure that i gonna crack NLU NLP thing crack down very soon. Introduction to Natural Language Processing NLP branch data science that consists systematic processes for analyzing, understanding, deriving information from text data in smart efficient manner. By utilizing NLP its components, one can organize massive chunks text data, perform numerous automated tasks solve wide range problems such as – automatic summarization, machine translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, topic segmentation etc.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer   \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "lemmatizer.lemmatize(noiseFreeData,pos=\"v\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
