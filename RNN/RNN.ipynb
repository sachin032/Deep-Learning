{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 137628 unique 80 \n"
     ]
    }
   ],
   "source": [
    "data = open(\"kafka.txt\",'r').read()\n",
    "chars = list(set(data))\n",
    "data_sizea, vocab_size =  len(data),len(chars)\n",
    "print(\"Data has %d unique %d \"%(data_sizea,vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ix = {ch: i for i , ch in enumerate(chars)}\n",
    "ix_to_char = {i:ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{':': 0, 'U': 1, 'A': 2, 'K': 3, 'e': 4, '4': 5, 'n': 6, 'R': 7, ',': 8, '.': 9, 'r': 10, 'y': 11, '1': 12, 'Q': 13, '5': 14, '!': 15, '?': 16, '0': 17, 'c': 18, '@': 19, ';': 20, 'D': 21, 'V': 22, '6': 23, '-': 24, 'T': 25, 'u': 26, 'p': 27, 'o': 28, 'W': 29, 'z': 30, 'N': 31, 'J': 32, '3': 33, ')': 34, 'j': 35, 'q': 36, 'O': 37, 't': 38, '/': 39, 'i': 40, 'S': 41, 'l': 42, 'H': 43, 'M': 44, 'L': 45, '7': 46, ' ': 47, '2': 48, 's': 49, 'X': 50, 'รง': 51, 'E': 52, '$': 53, 'f': 54, '\\n': 55, \"'\": 56, 'F': 57, 'g': 58, 'h': 59, 'd': 60, 'P': 61, '8': 62, '(': 63, '9': 64, '*': 65, 'k': 66, 'x': 67, 'a': 68, '%': 69, 'G': 70, '\"': 71, 'B': 72, 'v': 73, 'I': 74, 'b': 75, 'm': 76, 'C': 77, 'Y': 78, 'w': 79}\n",
      "{0: ':', 1: 'U', 2: 'A', 3: 'K', 4: 'e', 5: '4', 6: 'n', 7: 'R', 8: ',', 9: '.', 10: 'r', 11: 'y', 12: '1', 13: 'Q', 14: '5', 15: '!', 16: '?', 17: '0', 18: 'c', 19: '@', 20: ';', 21: 'D', 22: 'V', 23: '6', 24: '-', 25: 'T', 26: 'u', 27: 'p', 28: 'o', 29: 'W', 30: 'z', 31: 'N', 32: 'J', 33: '3', 34: ')', 35: 'j', 36: 'q', 37: 'O', 38: 't', 39: '/', 40: 'i', 41: 'S', 42: 'l', 43: 'H', 44: 'M', 45: 'L', 46: '7', 47: ' ', 48: '2', 49: 's', 50: 'X', 51: 'รง', 52: 'E', 53: '$', 54: 'f', 55: '\\n', 56: \"'\", 57: 'F', 58: 'g', 59: 'h', 60: 'd', 61: 'P', 62: '8', 63: '(', 64: '9', 65: '*', 66: 'k', 67: 'x', 68: 'a', 69: '%', 70: 'G', 71: '\"', 72: 'B', 73: 'v', 74: 'I', 75: 'b', 76: 'm', 77: 'C', 78: 'Y', 79: 'w'}\n"
     ]
    }
   ],
   "source": [
    "print(char_to_ix)\n",
    "print(ix_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create vector of size of number of unique charecters in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "vector_fro_char_a = np.zeros((vocab_size,1))\n",
    "vector_fro_char_a[char_to_ix['a']] = 1\n",
    "vector_fro_char_a.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size =  100 #network will consist of 100 neurons for it's hidden layer\n",
    "seq_length =  25  #there charecters that are going to be generated at every time stamp\n",
    "learning_rate  = 1e-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wxh = np.random.randn(hidden_size,vocab_size)* -0.01 #input to hidden state\n",
    "Whh = np.random.randn(hidden_size,hidden_size)* -0.01 #hidden to  to vocab state\n",
    "Why  = np.random.randn(vocab_size,hidden_size)* -0.01 #vocab_size to hidden state\n",
    "\n",
    "bh  = np.zeros((hidden_size,1)) # bias for hidden layer\n",
    "\n",
    "by = np.zeros((vocab_size,1))  # bias for Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
