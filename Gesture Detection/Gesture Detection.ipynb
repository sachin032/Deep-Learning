{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pprint\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense, LSTM, BatchNormalization, TimeDistributed, GRU\n",
    "from tensorflow.keras.activations import relu, softmax, sigmoid\n",
    "# from tensorflow import lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPTURE_WINDOW = 2\n",
    "\n",
    "### Sample time is 10ms ie sample rate = 1/10ms = 100hz\n",
    "SAMPLE_RATE = 100\n",
    "\n",
    "### Total samples per window\n",
    "SAMPLES = CAPTURE_WINDOW * SAMPLE_RATE\n",
    "FADE_LENGTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_to_fixed_size(d):\n",
    "    if len(d) >= SAMPLES:\n",
    "        d = d[0: SAMPLES]\n",
    "    elif len(d) < SAMPLES:\n",
    "        base_index = len(d) - FADE_LENGTH\n",
    "        for i in range(FADE_LENGTH):\n",
    "            r = float(i) / (FADE_LENGTH - 1)\n",
    "            d[base_index + i] = d[base_index + i] * (1 - r)\n",
    "        d.extend([0] * (SAMPLES - len(d)))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open(file) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        data = []\n",
    "        for i, row in enumerate(csv_reader):\n",
    "            d = []\n",
    "            ax = []\n",
    "            ay = []\n",
    "            az = []\n",
    "            gx = []\n",
    "            gy = []\n",
    "            gz = []\n",
    "            for i in range(0, len(row), 6):\n",
    "                try:\n",
    "                    ax.append(float(row[i + 0]))\n",
    "                    ay.append(float(row[i + 1]))\n",
    "                    az.append(float(row[i + 2]))\n",
    "                    gx.append(float(row[i + 3]))\n",
    "                    gy.append(float(row[i + 4]))\n",
    "                    gz.append(float(row[i + 5]))\n",
    "                except:\n",
    "                    pass;\n",
    "            # scale to fit into array of `SAMPLES`\n",
    "            ax = set_to_fixed_size(ax)\n",
    "            ay = set_to_fixed_size(ay)\n",
    "            az = set_to_fixed_size(az)\n",
    "            gx = set_to_fixed_size(gx)\n",
    "            gy = set_to_fixed_size(gy)\n",
    "            gz = set_to_fixed_size(gz)\n",
    "            for i in range(SAMPLES):\n",
    "                d.append([ax[i], ay[i], az[i], gx[i], gy[i], gz[i]])\n",
    "            data.append(d)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l = load_data('gesture.l.csv')\n",
    "data_o = load_data('gesture.o.csv')\n",
    "data_s = load_data('gesture.s.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = int((len(data_o) * 2) / 3)\n",
    "data_train_o = data_o[0: c]\n",
    "\n",
    "print(\"Train data o: \" + str(np.asarray(data_train_o).shape))\n",
    "\n",
    "data_test_o = data_o[c: len(data_o)]\n",
    "\n",
    "print.pprint(\"Test data o: \" + str(np.asarray(data_test_o).shape))\n",
    "\n",
    "c = int((len(data_s) * 2) / 3)\n",
    "data_train_s = data_s[0: c]\n",
    "\n",
    "print(\"Train data s: \" + str(np.asarray(data_train_s).shape))\n",
    "\n",
    "data_test_s = data_s[c: len(data_s)]\n",
    "\n",
    "print(\"Test data s: \" + str(np.asarray(data_test_s).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_L = 0\n",
    "LABEL_O = 1\n",
    "LABEL_S = 2\n",
    "\n",
    "data_train = []\n",
    "data_test = []\n",
    "\n",
    "data_train.extend(data_train_o)\n",
    "data_test.extend(data_test_o)\n",
    "data_train.extend(data_train_s)\n",
    "data_test.extend(data_test_s)\n",
    "data_train_label = []\n",
    "data_test_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_train_o)):\n",
    "    d = []\n",
    "    for j in range(SAMPLES):\n",
    "        d.append([1, 0])\n",
    "    data_train_label.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_train_s)):\n",
    "    d = []\n",
    "    for j in range(SAMPLES):\n",
    "        d.append([0, 1])\n",
    "    data_train_label.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_test_o)):\n",
    "    d = []\n",
    "    for j in range(SAMPLES):\n",
    "        d.append([1, 0])\n",
    "    data_test_label.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_test_s)):\n",
    "    d = []\n",
    "    for j in range(SAMPLES):\n",
    "        d.append([0, 1])\n",
    "    data_test_label.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.asarray(data_train)\n",
    "data_test = np.asarray(data_test)\n",
    "data_train_label = np.asarray(data_train_label)\n",
    "data_test_label = np.asarray(data_test_label)\n",
    "pprint.pprint(\"Train data: \" + str(data_train.shape))\n",
    "pprint.pprint(\"Train label: \" + str(data_train_label.shape))\n",
    "pprint.pprint(\"Test data: \" + str(data_test.shape))\n",
    "pprint.pprint(\"Test label: \" + str(data_test_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32, return_sequences = True, input_shape = (200, 6)))\n",
    "model.add(LSTM(16, return_sequences = True))\n",
    "model.add(Dense(2, activation = softmax))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(x = data_train, y = data_train_label, validation_data = (data_test, data_test_label), epochs = 100, batch_size = 1, verbose = 2)\n",
    "model.save('model.h5')\n",
    "\n",
    "data_test_predict = model.predict(data_test)\n",
    "output = np.argmax(data_test_predict[:, -1, :], axis = 1)\n",
    "pprint.pprint(\"out\")\n",
    "pprint.pprint(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
